# GKEë¥¼ í™œìš©í•œ Llama 3 íŒŒì¸íŠœë‹ ê°€ì´ë“œ

ì´ ë¬¸ì„œëŠ” Google Kubernetes Engine(GKE)ì˜ `a3-megagpu-8g` (NVIDIA H100 8 chips) ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ `meta-llama/Meta-Llama-3-8B-Instruct` ëª¨ë¸ì„ íŒŒì¸íŠœë‹ í•˜ëŠ” ì „ì²´ ê³¼ì •ì„ ì•ˆë‚´í•©ë‹ˆë‹¤. ë‹¨ì¼ ë…¸ë“œ(8 GPUs) ë° ë‹¤ì¤‘ ë…¸ë“œ(16 GPUs) ì„¤ì •ì— ëŒ€í•œ ì§€ì¹¨ì„ ëª¨ë‘ í¬í•¨í•©ë‹ˆë‹¤.

## í”„ë¡œì íŠ¸ ëª©í‘œ

-   `databricks/databricks-dolly-15k` ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•˜ì—¬ Llama 3 ëª¨ë¸ì„ íš¨ìœ¨ì ìœ¼ë¡œ íŒŒì¸ íŠœë‹í•©ë‹ˆë‹¤.
-   Workload Identityë¥¼ ì‚¬ìš©í•˜ì—¬ GKEì—ì„œ Google Cloud Storage(GCS)ë¡œ ì•ˆì „í•˜ê²Œ ëª¨ë¸ ì•„í‹°íŒ©íŠ¸ë¥¼ ì—…ë¡œë“œí•©ë‹ˆë‹¤.
-   ë‹¨ì¼ ë…¸ë“œ ë° ë‹¤ì¤‘ ë…¸ë“œ í•™ìŠµì„ ì¬í˜„í•  ìˆ˜ ìˆë„ë¡ Dockerfile, Kubernetes Job YAML, ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

---

## ì‚¬ì „ ì¤€ë¹„ ì‚¬í•­

1.  **Google Cloud Project**: ê²°ì œê°€ í™œì„±í™”ëœ GCP í”„ë¡œì íŠ¸ê°€ í•„ìš”í•©ë‹ˆë‹¤.
2.  **CLI ë„êµ¬**: `gcloud` CLIì™€ `kubectl`ì´ ë¡œì»¬ ë¨¸ì‹ ì— ì„¤ì¹˜ ë° ì¸ì¦ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
3.  **GKE í´ëŸ¬ìŠ¤í„°**: `a3-megagpu-8g` ë…¸ë“œ í’€ì´ êµ¬ì„±ëœ GKE í´ëŸ¬ìŠ¤í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.
    -   **ì°¸ê³ **: `a3-megagpu-8g`ëŠ” í• ë‹¹ëŸ‰ì´ í•„ìš”í•˜ë©°, `us-central1`ê³¼ ê°™ì€ íŠ¹ì • ë¦¬ì „ì—ì„œë§Œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
4.  **GCS Bucket**: íŒŒì¸íŠœë‹ ëœ ëª¨ë¸ ì•„í‹°íŒ©íŠ¸ë¥¼ ì €ì¥í•  GCS ë²„í‚·ì´ í•„ìš”í•©ë‹ˆë‹¤.
5.  **Hugging Face ê³„ì •**: Llama 3 ëª¨ë¸ì— ì ‘ê·¼í•˜ë ¤ë©´ Hugging Face ê³„ì •ê³¼ `hf_...` í˜•ì‹ì˜ ì•¡ì„¸ìŠ¤ í† í°ì´ í•„ìš”í•©ë‹ˆë‹¤.

---

## ì„¤ì • ë‹¨ê³„

### 1. ì„œë¹„ìŠ¤ ê³„ì • ë° ê¶Œí•œ ì„¤ì • (Workload Identity)

GKE íŒŒë“œê°€ GCSì— ì•ˆì „í•˜ê²Œ ì ‘ê·¼í•  ìˆ˜ ìˆë„ë¡ Workload Identityë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.

#### 1.1. IAM ì„œë¹„ìŠ¤ ê³„ì • ìƒì„±

```bash
# ë³€ìˆ˜ ì„¤ì • (ë³¸ì¸ì˜ í™˜ê²½ì— ë§ê²Œ ìˆ˜ì •í•˜ì„¸ìš”)
export PROJECT_ID="<YOUR_PROJECT_ID>"
export GCS_BUCKET_NAME="<YOUR_GCS_BUCKET_NAME>"
export IAM_SA_NAME="llama3-finetuner-sa"

# IAM ì„œë¹„ìŠ¤ ê³„ì • ìƒì„±
gcloud iam service-accounts create ${IAM_SA_NAME} \
  --project=${PROJECT_ID} \
  --display-name="Llama3 Finetuner Service Account"
```

#### 1.2. GCS ë²„í‚·ì— ëŒ€í•œ ê¶Œí•œ ë¶€ì—¬

ìƒì„±í•œ IAM ì„œë¹„ìŠ¤ ê³„ì •ì— GCS ë²„í‚·ì— ëŒ€í•œ `Storage Object Admin` ì—­í• ì„ ë¶€ì—¬í•©ë‹ˆë‹¤.

```bash
gcloud projects add-iam-policy-binding ${PROJECT_ID} \
    --member "serviceAccount:${IAM_SA_NAME}@${PROJECT_ID}.iam.gserviceaccount.com" \
    --role "roles/storage.objectAdmin"
```

#### 1.3. Kubernetes ì„œë¹„ìŠ¤ ê³„ì • ìƒì„± ë° ì—°ê²°

GKE í´ëŸ¬ìŠ¤í„°ì— Kubernetes ì„œë¹„ìŠ¤ ê³„ì •(KSA)ì„ ìƒì„±í•˜ê³ , IAM ì„œë¹„ìŠ¤ ê³„ì •ê³¼ ì—°ê²°í•©ë‹ˆë‹¤.

```bash
# ë³€ìˆ˜ ì„¤ì •
export K8S_SA_NAME="llama3-finetuner-ksa"
export NAMESPACE="default"

# Kubernetes ì„œë¹„ìŠ¤ ê³„ì • ìƒì„±
kubectl create serviceaccount ${K8S_SA_NAME} --namespace ${NAMESPACE}

# IAM ì„œë¹„ìŠ¤ ê³„ì •ê³¼ KSAë¥¼ ì—°ê²°í•˜ëŠ” ì–´ë…¸í…Œì´ì…˜ ì¶”ê°€
gcloud iam service-accounts add-iam-policy-binding ${IAM_SA_NAME}@${PROJECT_ID}.iam.gserviceaccount.com \
    --role roles/iam.workloadIdentityUser \
    --member "serviceAccount:${PROJECT_ID}.svc.id.goog[${NAMESPACE}/${K8S_SA_NAME}]"

# KSAì— Workload Identity ì–´ë…¸í…Œì´ì…˜ ì¶”ê°€
kubectl annotate serviceaccount ${K8S_SA_NAME} \
    --namespace ${NAMESPACE} \
    iam.gke.io/gcp-service-account=${IAM_SA_NAME}@${PROJECT_ID}.iam.gserviceaccount.com
```

### 2. Hugging Face ì•¡ì„¸ìŠ¤ í† í° Secret ìƒì„±

Hugging Face í† í°ì„ Kubernetes Secretìœ¼ë¡œ ì•ˆì „í•˜ê²Œ ì €ì¥í•©ë‹ˆë‹¤.

```bash
kubectl create secret generic huggingface-secret \
  --from-literal=token='<YOUR_HUGGING_FACE_TOKEN>'
```

### 3. Docker ì´ë¯¸ì§€ ë¹Œë“œ ë° í‘¸ì‹œ

ì œê³µëœ `Dockerfile`ì„ ì‚¬ìš©í•˜ì—¬ íŒŒì¸íŠœë‹ í™˜ê²½ì„ í¬í•¨í•˜ëŠ” Docker ì´ë¯¸ì§€ë¥¼ ë¹Œë“œí•˜ê³ , Google Artifact Registryì— í‘¸ì‹œí•©ë‹ˆë‹¤.

#### 3.1. Artifact Registry ë¦¬í¬ì§€í† ë¦¬ ìƒì„±

```bash
export PROJECT_ID="<YOUR_PROJECT_ID>"
export REGION="<YOUR_GCP_REGION>" # ì˜ˆ: us-central1
export AR_REPO="llama3-finetune-repo"

gcloud artifacts repositories create ${AR_REPO} \
    --repository-format=docker \
    --location=${REGION} \
    --description="Llama3 Finetuning Images"
```

#### 3.2. Docker ì´ë¯¸ì§€ ë¹Œë“œ ë° í‘¸ì‹œ

`push.sh` ìŠ¤í¬ë¦½íŠ¸ëŠ” ì´ ê³¼ì •ì„ ìë™í™”í•©ë‹ˆë‹¤. ìŠ¤í¬ë¦½íŠ¸ ë‚´ì˜ ë³€ìˆ˜ë¥¼ ìì‹ ì˜ í™˜ê²½ì— ë§ê²Œ ìˆ˜ì •í•˜ì„¸ìš”.

```bash
# push.sh (ë³¸ì¸ì˜ í™˜ê²½ì— ë§ê²Œ ìˆ˜ì •í•˜ì„¸ìš”)
export PROJECT_ID="<YOUR_PROJECT_ID>"
export REGION="<YOUR_GCP_REGION>"
export AR_REPO="llama3-finetune-repo"
export IMAGE_NAME="llama3-finetune"
export TAG="latest"

# ìµœì¢… ì´ë¯¸ì§€ URI
export IMAGE_URI="${REGION}-docker.pkg.dev/${PROJECT_ID}/${AR_REPO}/${IMAGE_NAME}:${TAG}"

# Docker ì´ë¯¸ì§€ ë¹Œë“œ ë° í‘¸ì‹œ
docker build -t ${IMAGE_URI} .
docker push ${IMAGE_URI}
```

ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.

```bash
bash push.sh
```

---

## ğŸš€ ë‹¨ì¼ ë…¸ë“œ íŒŒì¸íŠœë‹ (8 GPUs)

### 1. íŒŒì¸íŠœë‹ ì‘ì—… ì‹¤í–‰

`finetune-job.yaml` íŒŒì¼ì„ ì‚¬ìš©í•˜ì—¬ Kubernetes Jobì„ ì‹¤í–‰í•©ë‹ˆë‹¤. ì´ íŒŒì¼ì€ ë‹¨ì¼ `a3-megagpu-8g` ë…¸ë“œì—ì„œ 8ê°œì˜ GPUë¥¼ ëª¨ë‘ ì‚¬ìš©í•˜ë„ë¡ ì„¤ì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

**ì°¸ê³ :** `finetune-job.yaml` íŒŒì¼ ë‚´ì˜ `image` ê²½ë¡œë¥¼ ìœ„ ë‹¨ê³„ì—ì„œ í‘¸ì‹œí•œ ë³¸ì¸ì˜ Artifact Registry ì´ë¯¸ì§€ ê²½ë¡œë¡œ ìˆ˜ì •í•´ì•¼ í•©ë‹ˆë‹¤.

```bash
kubectl apply -f finetune-job.yaml
```

### 2. ëª¨ë‹ˆí„°ë§ ë° ê²°ê³¼ í™•ì¸

#### íŒŒë“œ ìƒíƒœ í™•ì¸
```bash
kubectl get pods -l job-name=llama3-finetune-job -w
```

#### ë¡œê·¸ ìŠ¤íŠ¸ë¦¬ë°
```bash
export POD_NAME=$(kubectl get pods -l job-name=llama3-finetune-job -o jsonpath='{.items[0].metadata.name}')
kubectl logs -f $POD_NAME
```

í•™ìŠµì´ ì™„ë£Œë˜ë©´ `train_loss`ì™€ í•¨ê»˜ GCS ì—…ë¡œë“œ ì™„ë£Œ ë©”ì‹œì§€ê°€ ì¶œë ¥ë©ë‹ˆë‹¤.

#### GCS ë²„í‚· ê²°ê³¼ í™•ì¸
```bash
gsutil ls gs://<YOUR_GCS_BUCKET_NAME>/final_model/
```

---

## ğŸš€ ë‹¤ì¤‘ ë…¸ë“œ íŒŒì¸íŠœë‹ (16 GPUs)

ì´ ì„¤ì •ì€ 2ê°œì˜ `a3-megagpu-8g` ë…¸ë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ 16ê°œì˜ GPUë¡œ ë¶„ì‚° í•™ìŠµì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. PyTorchì˜ `torchrun`ì„ ì‚¬ìš©í•˜ì—¬ ë¶„ì‚° í™˜ê²½ì„ êµ¬ì„±í•©ë‹ˆë‹¤.

### 1. GKE ë…¸ë“œ í’€ í™•ì¥

`a3-megagpu-8g`ë¥¼ ì‚¬ìš©í•˜ëŠ” ë…¸ë“œ í’€ì˜ í¬ê¸°ë¥¼ 2ë¡œ í™•ì¥í•©ë‹ˆë‹¤.

```bash
# ë³€ìˆ˜ ì„¤ì •
export CLUSTER_NAME="<YOUR_CLUSTER_NAME>"
export NODE_POOL_NAME="<YOUR_NODE_POOL_NAME>"
export REGION="<YOUR_GCP_REGION>"

# ë…¸ë“œ í’€ í¬ê¸° ì¡°ì •
gcloud container clusters resize ${CLUSTER_NAME} \
    --node-pool=${NODE_POOL_NAME} \
    --num-nodes=2 \
    --region=${REGION}
```

### 2. ë‹¤ì¤‘ ë…¸ë“œ ì‘ì—… ì‹¤í–‰

`finetune-job-multinode.yaml`ì€ `torchrun`ì„ ì‚¬ìš©í•˜ì—¬ 2ê°œì˜ ë…¸ë“œì—ì„œ ë¶„ì‚° í•™ìŠµì„ ì‹¤í–‰í•˜ë„ë¡ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

**ì£¼ìš” ì„¤ì •:**
-   **Headless Service:** íŒŒë“œ ê°„ì˜ ì•ˆì •ì ì¸ í†µì‹ ì„ ìœ„í•´ `clusterIP: None`ìœ¼ë¡œ ì„¤ì •ëœ í—¤ë“œë¦¬ìŠ¤ ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
-   **Indexed Job:** `completionMode: Indexed`ë¥¼ ì‚¬ìš©í•˜ì—¬ ê° íŒŒë“œì— ê³ ìœ í•œ ì¸ë±ìŠ¤(0 ë˜ëŠ” 1)ë¥¼ ë¶€ì—¬í•©ë‹ˆë‹¤. ì´ ì¸ë±ìŠ¤ëŠ” `JOB_COMPLETION_INDEX` í™˜ê²½ ë³€ìˆ˜ë¥¼ í†µí•´ ì»¨í…Œì´ë„ˆ ë‚´ë¶€ë¡œ ì „ë‹¬ë˜ì–´ `torchrun`ì˜ `node_rank`ë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤.
-   **torchrun:** `command` ì„¹ì…˜ì—ì„œ `torchrun`ì„ ì§ì ‘ í˜¸ì¶œí•˜ì—¬ `--nnodes=2`, `--nproc_per_node=8` ë“±ì˜ ë¶„ì‚° í•™ìŠµ íŒŒë¼ë¯¸í„°ë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.
-   **NCCL í™˜ê²½ ë³€ìˆ˜:** `NCCL_SOCKET_IFNAME=eth0`ë¥¼ ì„¤ì •í•˜ì—¬ ë‹¤ì¤‘ ë…¸ë“œ í†µì‹ ì— ì‚¬ìš©í•  ë„¤íŠ¸ì›Œí¬ ì¸í„°í˜ì´ìŠ¤ë¥¼ ì§€ì •í•©ë‹ˆë‹¤.

**ì°¸ê³ :** `finetune-job-multinode.yaml` íŒŒì¼ ë‚´ì˜ `image` ê²½ë¡œë¥¼ ë³¸ì¸ì˜ Artifact Registry ì´ë¯¸ì§€ ê²½ë¡œë¡œ ìˆ˜ì •í•´ì•¼ í•©ë‹ˆë‹¤.

```bash
kubectl apply -f finetune-job-multinode.yaml
```

### 3. ëª¨ë‹ˆí„°ë§ ë° ê²°ê³¼ í™•ì¸

#### íŒŒë“œ ìƒíƒœ í™•ì¸
```bash
kubectl get pods -l job-name=llama3-finetune-job-multinode -w
```

#### ê° íŒŒë“œ ë¡œê·¸ ìŠ¤íŠ¸ë¦¬ë°

ë‘ íŒŒë“œì˜ ë¡œê·¸ë¥¼ ê°ê° í™•ì¸í•˜ì—¬ í•™ìŠµì´ ë™ê¸°í™”ë˜ì–´ ì§„í–‰ë˜ëŠ”ì§€ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```bash
# RANK 0 íŒŒë“œ ë¡œê·¸
export POD_NAME_0=$(kubectl get pods -l job-name=llama3-finetune-job-multinode,batch.kubernetes.io/job-completion-index=0 -o jsonpath='{.items[0].metadata.name}')
kubectl logs -f $POD_NAME_0

# RANK 1 íŒŒë“œ ë¡œê·¸
export POD_NAME_1=$(kubectl get pods -l job-name=llama3-finetune-job-multinode,batch.kubernetes.io/job-completion-index=1 -o jsonpath='{.items[0].metadata.name}')
kubectl logs -f $POD_NAME_1
```

í•™ìŠµì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ë©´, RANK 0 íŒŒë“œì—ì„œ ëª¨ë¸ì„ GCSì— ì—…ë¡œë“œí•˜ëŠ” ë¡œê·¸ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

---

## íŒŒì¼ ì„¤ëª…

-   **`Dockerfile`**: íŒŒì¸ íŠœë‹ í™˜ê²½ì„ ìœ„í•œ Docker ì´ë¯¸ì§€ë¥¼ ë¹Œë“œí•˜ëŠ” íŒŒì¼ì…ë‹ˆë‹¤.
-   **`finetune-job.yaml`**: ë‹¨ì¼ ë…¸ë“œ GKE íŒŒì¸ íŠœë‹ Jobì„ ìœ„í•œ Kubernetes ëª…ì„¸ íŒŒì¼ì…ë‹ˆë‹¤.
-   **`finetune-job-multinode.yaml`**: ë‹¤ì¤‘ ë…¸ë“œ ë¶„ì‚° í•™ìŠµì„ ìœ„í•œ Kubernetes Service ë° Job ëª…ì„¸ íŒŒì¼ì…ë‹ˆë‹¤.
-   **`scripts/finetune.py`**: ì‹¤ì œ ëª¨ë¸ ë¡œë“œ, ë°ì´í„° ì²˜ë¦¬, íŒŒì¸ íŠœë‹ ë° GCS ì—…ë¡œë“œë¥¼ ìˆ˜í–‰í•˜ëŠ” Python ìŠ¤í¬ë¦½íŠ¸ì…ë‹ˆë‹¤.
-   **`push.sh`**: `Dockerfile`ì„ ë¹Œë“œí•˜ê³  Google Artifact Registryì— ì´ë¯¸ì§€ë¥¼ í‘¸ì‹œí•˜ëŠ” ê³¼ì •ì„ ìë™í™”í•˜ëŠ” ì…¸ ìŠ¤í¬ë¦½íŠ¸ì…ë‹ˆë‹¤.