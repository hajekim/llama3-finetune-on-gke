# ë‹¤ì¤‘ ë…¸ë“œ í†µì‹ ì„ ìœ„í•œ í—¤ë“œë¦¬ìŠ¤ ì„œë¹„ìŠ¤
apiVersion: v1
kind: Service
metadata:
  name: llama3-finetune-job-headless
spec:
  clusterIP: None # í—¤ë“œë¦¬ìŠ¤ ì„œë¹„ìŠ¤
  selector:
    job-name: llama3-finetune-job-multinode # ì•„ë˜ Jobì˜ íŒŒë“œì™€ ì—°ê²°

---

# ë‹¤ì¤‘ ë…¸ë“œ ë¯¸ì„¸ ì¡°ì • ì‘ì—…ì„ ìœ„í•œ Kubernetes Job
apiVersion: batch/v1
kind: Job
metadata:
  name: llama3-finetune-job-multinode
spec:
  completions: 2 # 2ê°œì˜ íŒŒë“œê°€ ëª¨ë‘ ì„±ê³µí•´ì•¼ Jobì´ ì™„ë£Œë¨
  parallelism: 2 # 2ê°œì˜ íŒŒë“œë¥¼ ë™ì‹œì— ì‹¤í–‰
  completionMode: Indexed # íŒŒë“œì— 0, 1, ... ì¸ë±ìŠ¤ë¥¼ ë¶€ì—¬
  template:
    spec:
      serviceAccountName: llama3-finetuner-ksa
      restartPolicy: Never
      nodeSelector:
        cloud.google.com/gke-accelerator: nvidia-h100-mega-80gb
      containers:
      - name: finetuner
        image: <YOUR_IMAGE_URI> # ğŸš¨ push.shë¡œ ë¹Œë“œí•œ ë³¸ì¸ì˜ ì´ë¯¸ì§€ URIë¡œ ë³€ê²½í•˜ì„¸ìš”.
        command:
        - "bash"
        - "-c"
        - |
          # MASTER_ADDRì€ í—¤ë“œë¦¬ìŠ¤ ì„œë¹„ìŠ¤ì˜ FQDNìœ¼ë¡œ ì„¤ì •
          export MASTER_ADDR="llama3-finetune-job-headless.default.svc.cluster.local"
          export MASTER_PORT="29500" # ê¸°ë³¸ í¬íŠ¸
          export WORLD_SIZE="2" # ì „ì²´ íŒŒë“œ ìˆ˜
          # JOB_COMPLETION_INDEXëŠ” Kubernetesê°€ ìë™ìœ¼ë¡œ ì£¼ì… (0 ë˜ëŠ” 1)
          export RANK="${JOB_COMPLETION_INDEX}"

          echo "Starting multi-node training..."
          echo "MASTER_ADDR: ${MASTER_ADDR}"
          echo "RANK: ${RANK}"
          echo "WORLD_SIZE: ${WORLD_SIZE}"

          torchrun \
            --nproc_per_node=8 \
            --nnodes=2 \
            --node_rank=${RANK} \
            --master_addr=${MASTER_ADDR} \
            --master_port=${MASTER_PORT} \
            /app/scripts/finetune.py
        env:
        - name: GCS_BUCKET_NAME
          value: "<YOUR_GCS_BUCKET_NAME>" # ğŸš¨ ë³¸ì¸ì˜ GCS ë²„í‚· ì´ë¦„ìœ¼ë¡œ ë³€ê²½í•˜ì„¸ìš”.
        - name: NCCL_SOCKET_IFNAME
          value: "eth0"
        - name: NCCL_DEBUG
          value: "INFO"
        - name: HUGGING_FACE_HUB_TOKEN
          valueFrom:
            secretKeyRef:
              name: huggingface-secret
              key: token
        - name: JOB_COMPLETION_INDEX # downward APIë¥¼ í†µí•´ íŒŒë“œ ì¸ë±ìŠ¤ë¥¼ í™˜ê²½ ë³€ìˆ˜ë¡œ ì£¼ì…
          valueFrom:
            fieldRef:
              fieldPath: metadata.annotations['batch.kubernetes.io/job-completion-index']
        resources:
          limits:
            nvidia.com/gpu: 8
        securityContext:
          privileged: true
        volumeMounts:
        - mountPath: /dev/shm
          name: dshm
      volumes:
      - name: dshm
        emptyDir:
          medium: Memory
          sizeLimit: 128Gi
      hostIPC: true
      tolerations:
      - key: "nvidia.com/gpu"
        operator: "Exists"
        effect: "NoSchedule"
